{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:00:01.852639Z","iopub.execute_input":"2025-12-04T09:00:01.852845Z","iopub.status.idle":"2025-12-04T09:00:06.176085Z","shell.execute_reply.started":"2025-12-04T09:00:01.852827Z","shell.execute_reply":"2025-12-04T09:00:06.174969Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.20.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.10.5)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import gdown\n\ngdown.download(\"https://drive.google.com/uc?id=1f8eaAZY-7YgFxLcrL3OkvSRa3onNNLb9\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:00:06.177313Z","iopub.execute_input":"2025-12-04T09:00:06.177664Z","iopub.status.idle":"2025-12-04T09:00:12.963489Z","shell.execute_reply.started":"2025-12-04T09:00:06.177626Z","shell.execute_reply":"2025-12-04T09:00:12.962914Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1f8eaAZY-7YgFxLcrL3OkvSRa3onNNLb9\nFrom (redirected): https://drive.google.com/uc?id=1f8eaAZY-7YgFxLcrL3OkvSRa3onNNLb9&confirm=t&uuid=5babadb0-8328-4936-9033-5b04b5bb15b6\nTo: /kaggle/working/midterm-regresi-dataset.csv\n100%|██████████| 443M/443M [00:04<00:00, 99.5MB/s] \n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'midterm-regresi-dataset.csv'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n\n# Dataset ini tidak punya header.\n# Nilai seperti 2001 di kolom pertama adalah TARGET (tahun), bukan nama feature /  kolom.INI Pathnya kalau di colab diubah soalnya pake kaggle jadi bukan yang content/\nfile_path = 'midterm-regresi-dataset.csv'\ndf = pd.read_csv(file_path)\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:00:12.965186Z","iopub.execute_input":"2025-12-04T09:00:12.965548Z","iopub.status.idle":"2025-12-04T09:00:20.507428Z","shell.execute_reply.started":"2025-12-04T09:00:12.965529Z","shell.execute_reply":"2025-12-04T09:00:20.506525Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   2001  49.94357  21.47114   73.0775   8.74861  -17.40628  -13.09905  \\\n0  2001  48.73215  18.42930  70.32679  12.94636  -10.32437  -24.83777   \n1  2001  50.95714  31.85602  55.81851  13.41693   -6.57898  -18.54940   \n2  2001  48.24750  -1.89837  36.29772   2.58776    0.97170  -26.21683   \n3  2001  50.97020  42.20998  67.09964   8.46791  -15.85279  -16.81409   \n4  2001  50.54767   0.31568  92.35066  22.38696  -25.51870  -19.04928   \n\n   -25.01202  -12.23257   7.83089  ...   13.0162  -54.40548  58.99367  \\\n0    8.76630   -0.92019  18.76548  ...   5.66812  -19.68073  33.04964   \n1   -3.27872   -2.35035  16.07017  ...   3.03800   26.05866 -50.92779   \n2    5.05097  -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705   \n3  -12.48207   -9.37636  12.63699  ...   9.92661  -55.95724  64.92712   \n4   20.67345   -5.19943   3.63566  ...   6.59753  -50.69577  26.02574   \n\n   15.37344   1.11144  -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n0  42.87836  -9.90378  -32.22788   70.49388  12.04941   58.43453  26.92061  \n1  10.93792  -0.07568   43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n2 -46.67617 -12.51516   82.58061  -72.08993   9.90558  199.62971  18.85382  \n3 -17.72522  -1.49237   -7.50035   51.76631   7.88713   55.66926  28.74903  \n4  18.94430  -0.33730    6.09352   35.18381   5.00283  -11.02257   0.02263  \n\n[5 rows x 91 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2001</th>\n      <th>49.94357</th>\n      <th>21.47114</th>\n      <th>73.0775</th>\n      <th>8.74861</th>\n      <th>-17.40628</th>\n      <th>-13.09905</th>\n      <th>-25.01202</th>\n      <th>-12.23257</th>\n      <th>7.83089</th>\n      <th>...</th>\n      <th>13.0162</th>\n      <th>-54.40548</th>\n      <th>58.99367</th>\n      <th>15.37344</th>\n      <th>1.11144</th>\n      <th>-23.08793</th>\n      <th>68.40795</th>\n      <th>-1.82223</th>\n      <th>-27.46348</th>\n      <th>2.26327</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001</td>\n      <td>48.73215</td>\n      <td>18.42930</td>\n      <td>70.32679</td>\n      <td>12.94636</td>\n      <td>-10.32437</td>\n      <td>-24.83777</td>\n      <td>8.76630</td>\n      <td>-0.92019</td>\n      <td>18.76548</td>\n      <td>...</td>\n      <td>5.66812</td>\n      <td>-19.68073</td>\n      <td>33.04964</td>\n      <td>42.87836</td>\n      <td>-9.90378</td>\n      <td>-32.22788</td>\n      <td>70.49388</td>\n      <td>12.04941</td>\n      <td>58.43453</td>\n      <td>26.92061</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2001</td>\n      <td>50.95714</td>\n      <td>31.85602</td>\n      <td>55.81851</td>\n      <td>13.41693</td>\n      <td>-6.57898</td>\n      <td>-18.54940</td>\n      <td>-3.27872</td>\n      <td>-2.35035</td>\n      <td>16.07017</td>\n      <td>...</td>\n      <td>3.03800</td>\n      <td>26.05866</td>\n      <td>-50.92779</td>\n      <td>10.93792</td>\n      <td>-0.07568</td>\n      <td>43.20130</td>\n      <td>-115.00698</td>\n      <td>-0.05859</td>\n      <td>39.67068</td>\n      <td>-0.66345</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2001</td>\n      <td>48.24750</td>\n      <td>-1.89837</td>\n      <td>36.29772</td>\n      <td>2.58776</td>\n      <td>0.97170</td>\n      <td>-26.21683</td>\n      <td>5.05097</td>\n      <td>-10.34124</td>\n      <td>3.55005</td>\n      <td>...</td>\n      <td>34.57337</td>\n      <td>-171.70734</td>\n      <td>-16.96705</td>\n      <td>-46.67617</td>\n      <td>-12.51516</td>\n      <td>82.58061</td>\n      <td>-72.08993</td>\n      <td>9.90558</td>\n      <td>199.62971</td>\n      <td>18.85382</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001</td>\n      <td>50.97020</td>\n      <td>42.20998</td>\n      <td>67.09964</td>\n      <td>8.46791</td>\n      <td>-15.85279</td>\n      <td>-16.81409</td>\n      <td>-12.48207</td>\n      <td>-9.37636</td>\n      <td>12.63699</td>\n      <td>...</td>\n      <td>9.92661</td>\n      <td>-55.95724</td>\n      <td>64.92712</td>\n      <td>-17.72522</td>\n      <td>-1.49237</td>\n      <td>-7.50035</td>\n      <td>51.76631</td>\n      <td>7.88713</td>\n      <td>55.66926</td>\n      <td>28.74903</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>50.54767</td>\n      <td>0.31568</td>\n      <td>92.35066</td>\n      <td>22.38696</td>\n      <td>-25.51870</td>\n      <td>-19.04928</td>\n      <td>20.67345</td>\n      <td>-5.19943</td>\n      <td>3.63566</td>\n      <td>...</td>\n      <td>6.59753</td>\n      <td>-50.69577</td>\n      <td>26.02574</td>\n      <td>18.94430</td>\n      <td>-0.33730</td>\n      <td>6.09352</td>\n      <td>35.18381</td>\n      <td>5.00283</td>\n      <td>-11.02257</td>\n      <td>0.02263</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 91 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\"df.shape:\", df.shape) #ada 515344 row/baris dan 90 feature","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:00:20.508326Z","iopub.execute_input":"2025-12-04T09:00:20.508914Z","iopub.status.idle":"2025-12-04T09:00:20.513262Z","shell.execute_reply.started":"2025-12-04T09:00:20.508887Z","shell.execute_reply":"2025-12-04T09:00:20.512382Z"}},"outputs":[{"name":"stdout","text":"df.shape: (515344, 91)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nfile_size_bytes = os.path.getsize(file_path)\nfile_size_mb = file_size_bytes / (1024 ** 2)\n\nprint(f\"Ukuran file: {file_size_bytes:,} bytes\")\nprint(f\"Ukuran file: {file_size_mb:.2f} MB\")  #ukuran 422.88 MB, deadline 2 minggu. ngerjain mepet pasti ga kelar :))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:00:20.514061Z","iopub.execute_input":"2025-12-04T09:00:20.514630Z","iopub.status.idle":"2025-12-04T09:00:21.003601Z","shell.execute_reply.started":"2025-12-04T09:00:20.514601Z","shell.execute_reply":"2025-12-04T09:00:21.002707Z"}},"outputs":[{"name":"stdout","text":"Ukuran file: 443,423,087 bytes\nUkuran file: 422.88 MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport os\n\n# TensorFlow / Keras Imports\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TensorFlow warnings\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Scikit-learn Imports for Preprocessing and Evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:05:33.169760Z","iopub.execute_input":"2025-12-04T09:05:33.170298Z","iopub.status.idle":"2025-12-04T09:05:46.722293Z","shell.execute_reply.started":"2025-12-04T09:05:33.170272Z","shell.execute_reply":"2025-12-04T09:05:46.721505Z"}},"outputs":[{"name":"stderr","text":"2025-12-04 09:05:34.297363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764839134.440805      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764839134.483207      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"# --- 1. Data Loading and Initial Setup ---\nprint(\"--- 1. Data Loading and Initial Setup ---\")\n\nfile_path = 'midterm-regresi-dataset.csv'\n\n# Since the dataset has no header, we manually create column names.\nfeature_cols = [f'feature_{i}' for i in range(1, 91)]\ncolumn_names = ['target'] + feature_cols\n\n# Load the dataset\ntry:\n    df = pd.read_csv(file_path, header=None, names=column_names)\nexcept FileNotFoundError:\n    print(f\"Error: File not found at {file_path}. Please ensure the file is in the correct directory.\")\n    exit()\n\nprint(f\"Dataset loaded. Total shape: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:06:07.387746Z","iopub.execute_input":"2025-12-04T09:06:07.388626Z","iopub.status.idle":"2025-12-04T09:06:14.407967Z","shell.execute_reply.started":"2025-12-04T09:06:07.388595Z","shell.execute_reply":"2025-12-04T09:06:14.407269Z"}},"outputs":[{"name":"stdout","text":"--- 1. Data Loading and Initial Setup ---\nDataset loaded. Total shape: (515345, 91)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# --- 2. Data Sampling and Target Standardization ---\nprint(\"\\n--- 2. Data Sampling and Target Standardization ---\")\n# Use a sample for demonstration. Change SAMPLE_FRACTION to 1.0 to use the full dataset.\nSAMPLE_FRACTION = 1\n\nif SAMPLE_FRACTION < 1.0:\n    print(f\"Status: Using a sample. Sampling {SAMPLE_FRACTION*100:.0f}% of the data.\")\n    df_sample = df.sample(frac=SAMPLE_FRACTION, random_state=42).copy()\nelse:\n    print(\"Status: Using the full dataset (SAMPLE_FRACTION = 1.0).\")\n    df_sample = df.copy()\n\nprint(f\"Sampled Dataset Shape: {df_sample.shape}\")\n\n# Separate features (X) and target (y)\nX = df_sample.drop('target', axis=1)\ny = df_sample['target'].copy()\nnumerical_features = X.columns.tolist()\n\n# The target variable (year, e.g., 2001) is often large.\n# Standardizing the target helps Deep Learning models converge faster.\ntarget_mean = y.mean()\ntarget_std = y.std()\n\n# Target Standardization: y_scaled = (y - mean) / std\ny_scaled = (y - target_mean) / target_std\nprint(f\"Target variable (Year) standardized. Mean: {target_mean:.2f}, Std Dev: {target_std:.2f}\")\n\n# Split data into training and testing sets\nX_train, X_test, y_train_scaled, y_test_scaled = train_test_split(\n    X, y_scaled, test_size=0.2, random_state=42\n)\ny_test_original = y.loc[y_test_scaled.index] # Keep original years for final reporting\n\nprint(f\"Training set size: {X_train.shape[0]} rows\")\nprint(f\"Test set size: {X_test.shape[0]} rows\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:08:47.404217Z","iopub.execute_input":"2025-12-04T09:08:47.404908Z","iopub.status.idle":"2025-12-04T09:08:48.025957Z","shell.execute_reply.started":"2025-12-04T09:08:47.404881Z","shell.execute_reply":"2025-12-04T09:08:48.025112Z"}},"outputs":[{"name":"stdout","text":"\n--- 2. Data Sampling and Target Standardization ---\nStatus: Using the full dataset (SAMPLE_FRACTION = 1.0).\nSampled Dataset Shape: (515345, 91)\nTarget variable (Year) standardized. Mean: 1998.40, Std Dev: 10.93\nTraining set size: 412276 rows\nTest set size: 103069 rows\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# --- 3. Data Preprocessing Pipeline (Feature Scaling) ---\nprint(\"\\n--- 3. Data Preprocessing Pipeline (Feature Scaling) ---\")\n\n# We only need scaling for the features, as the target is handled above.\nnumerical_pipeline = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Create a ColumnTransformer to apply the scaling to all 90 features\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_pipeline, numerical_features)\n    ],\n    remainder='passthrough',\n    n_jobs=-1\n)\n\n# Apply preprocessing and convert to NumPy array for TensorFlow\nX_train_processed = preprocessor.fit_transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\nprint(f\"Features processed. Training shape: {X_train_processed.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:08:54.352479Z","iopub.execute_input":"2025-12-04T09:08:54.353238Z","iopub.status.idle":"2025-12-04T09:09:04.268210Z","shell.execute_reply.started":"2025-12-04T09:08:54.353213Z","shell.execute_reply":"2025-12-04T09:09:04.267485Z"}},"outputs":[{"name":"stdout","text":"\n--- 3. Data Preprocessing Pipeline (Feature Scaling) ---\nFeatures processed. Training shape: (412276, 90)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# --- 4. TensorFlow Model Definition (MLP) ---\nprint(\"\\n--- 4. TensorFlow Model Definition (MLP) ---\")\n\ninput_shape = X_train_processed.shape[1]\nprint(f\"Input Features: {input_shape}\")\n\n# Simple Multi-Layer Perceptron (MLP) for Regression\ndef create_mlp_model(input_dim):\n    model = Sequential([\n        # Input Layer: 90 features\n        Dense(128, activation='relu', input_shape=(input_dim,)),\n        Dropout(0.2), # Dropout for regularization\n        \n        # Hidden Layer 1\n        Dense(64, activation='relu'),\n        \n        # Hidden Layer 2\n        Dense(32, activation='relu'),\n        \n        # Output Layer: 1 unit for the scaled target value\n        Dense(1, activation='linear') \n    ])\n    \n    # Compile the model\n    # Using 'Adam' optimizer and 'mse' loss for regression on scaled target\n    model.compile(optimizer=Adam(learning_rate=0.001), \n                  loss='mse', \n                  metrics=['mae', 'mse'])\n    return model\n\nmodel = create_mlp_model(input_shape)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:09:14.329046Z","iopub.execute_input":"2025-12-04T09:09:14.329332Z","iopub.status.idle":"2025-12-04T09:09:14.377854Z","shell.execute_reply.started":"2025-12-04T09:09:14.329310Z","shell.execute_reply":"2025-12-04T09:09:14.377261Z"}},"outputs":[{"name":"stdout","text":"\n--- 4. TensorFlow Model Definition (MLP) ---\nInput Features: 90\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m11,648\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,648</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,017\u001b[0m (86.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,017</span> (86.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,017\u001b[0m (86.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,017</span> (86.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# --- 5. Model Training and Early Stopping ---\nprint(\"\\n--- 5. Model Training and Early Stopping ---\")\n\n# Define callbacks for stable and efficient training\n# EarlyStopping: Stop if validation loss doesn't improve for 5 epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n\nEPOCHS = 100 \nBATCH_SIZE = 64 # Use a common batch size for large datasets\n\nstart_time = time.time()\nhistory = model.fit(\n    X_train_processed, y_train_scaled,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    validation_split=0.1, # Use 10% of training data for validation\n    callbacks=[early_stopping],\n    verbose=2 # Verbose 2 shows progress per epoch\n)\ntraining_duration = time.time() - start_time\n\nprint(f\"\\nTraining Duration: {training_duration:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:09:22.641052Z","iopub.execute_input":"2025-12-04T09:09:22.641338Z","iopub.status.idle":"2025-12-04T09:16:40.139799Z","shell.execute_reply.started":"2025-12-04T09:09:22.641317Z","shell.execute_reply":"2025-12-04T09:16:40.138973Z"}},"outputs":[{"name":"stdout","text":"\n--- 5. Model Training and Early Stopping ---\nEpoch 1/100\n5798/5798 - 17s - 3ms/step - loss: 0.7009 - mae: 0.5854 - mse: 0.7009 - val_loss: 0.6483 - val_mae: 0.5507 - val_mse: 0.6483\nEpoch 2/100\n5798/5798 - 14s - 2ms/step - loss: 0.6541 - mae: 0.5599 - mse: 0.6541 - val_loss: 0.6309 - val_mae: 0.5508 - val_mse: 0.6309\nEpoch 3/100\n5798/5798 - 14s - 2ms/step - loss: 0.6406 - mae: 0.5537 - mse: 0.6406 - val_loss: 0.6245 - val_mae: 0.5496 - val_mse: 0.6245\nEpoch 4/100\n5798/5798 - 14s - 2ms/step - loss: 0.6332 - mae: 0.5502 - mse: 0.6332 - val_loss: 0.6177 - val_mae: 0.5403 - val_mse: 0.6177\nEpoch 5/100\n5798/5798 - 14s - 2ms/step - loss: 0.6269 - mae: 0.5472 - mse: 0.6269 - val_loss: 0.6181 - val_mae: 0.5427 - val_mse: 0.6181\nEpoch 6/100\n5798/5798 - 14s - 2ms/step - loss: 0.6224 - mae: 0.5450 - mse: 0.6224 - val_loss: 0.6142 - val_mae: 0.5392 - val_mse: 0.6142\nEpoch 7/100\n5798/5798 - 14s - 2ms/step - loss: 0.6165 - mae: 0.5425 - mse: 0.6165 - val_loss: 0.6136 - val_mae: 0.5473 - val_mse: 0.6136\nEpoch 8/100\n5798/5798 - 13s - 2ms/step - loss: 0.6125 - mae: 0.5407 - mse: 0.6125 - val_loss: 0.6118 - val_mae: 0.5372 - val_mse: 0.6118\nEpoch 9/100\n5798/5798 - 14s - 2ms/step - loss: 0.6107 - mae: 0.5400 - mse: 0.6107 - val_loss: 0.6092 - val_mae: 0.5363 - val_mse: 0.6092\nEpoch 10/100\n5798/5798 - 14s - 2ms/step - loss: 0.6074 - mae: 0.5382 - mse: 0.6074 - val_loss: 0.6099 - val_mae: 0.5360 - val_mse: 0.6099\nEpoch 11/100\n5798/5798 - 14s - 2ms/step - loss: 0.6038 - mae: 0.5371 - mse: 0.6038 - val_loss: 0.6126 - val_mae: 0.5350 - val_mse: 0.6126\nEpoch 12/100\n5798/5798 - 14s - 2ms/step - loss: 0.6005 - mae: 0.5360 - mse: 0.6005 - val_loss: 0.6085 - val_mae: 0.5352 - val_mse: 0.6085\nEpoch 13/100\n5798/5798 - 14s - 2ms/step - loss: 0.5993 - mae: 0.5353 - mse: 0.5993 - val_loss: 0.6088 - val_mae: 0.5399 - val_mse: 0.6088\nEpoch 14/100\n5798/5798 - 13s - 2ms/step - loss: 0.5970 - mae: 0.5341 - mse: 0.5970 - val_loss: 0.6091 - val_mae: 0.5387 - val_mse: 0.6091\nEpoch 15/100\n5798/5798 - 14s - 2ms/step - loss: 0.5950 - mae: 0.5338 - mse: 0.5950 - val_loss: 0.6075 - val_mae: 0.5402 - val_mse: 0.6075\nEpoch 16/100\n5798/5798 - 14s - 2ms/step - loss: 0.5928 - mae: 0.5327 - mse: 0.5928 - val_loss: 0.6051 - val_mae: 0.5331 - val_mse: 0.6051\nEpoch 17/100\n5798/5798 - 13s - 2ms/step - loss: 0.5908 - mae: 0.5318 - mse: 0.5908 - val_loss: 0.6050 - val_mae: 0.5366 - val_mse: 0.6050\nEpoch 18/100\n5798/5798 - 14s - 2ms/step - loss: 0.5888 - mae: 0.5309 - mse: 0.5888 - val_loss: 0.6057 - val_mae: 0.5321 - val_mse: 0.6057\nEpoch 19/100\n5798/5798 - 13s - 2ms/step - loss: 0.5876 - mae: 0.5304 - mse: 0.5876 - val_loss: 0.6055 - val_mae: 0.5306 - val_mse: 0.6055\nEpoch 20/100\n5798/5798 - 13s - 2ms/step - loss: 0.5849 - mae: 0.5294 - mse: 0.5849 - val_loss: 0.6047 - val_mae: 0.5331 - val_mse: 0.6047\nEpoch 21/100\n5798/5798 - 13s - 2ms/step - loss: 0.5834 - mae: 0.5285 - mse: 0.5834 - val_loss: 0.6040 - val_mae: 0.5356 - val_mse: 0.6040\nEpoch 22/100\n5798/5798 - 13s - 2ms/step - loss: 0.5822 - mae: 0.5279 - mse: 0.5822 - val_loss: 0.6077 - val_mae: 0.5295 - val_mse: 0.6077\nEpoch 23/100\n5798/5798 - 13s - 2ms/step - loss: 0.5810 - mae: 0.5275 - mse: 0.5810 - val_loss: 0.6053 - val_mae: 0.5385 - val_mse: 0.6053\nEpoch 24/100\n5798/5798 - 13s - 2ms/step - loss: 0.5798 - mae: 0.5274 - mse: 0.5798 - val_loss: 0.6061 - val_mae: 0.5400 - val_mse: 0.6061\nEpoch 25/100\n5798/5798 - 13s - 2ms/step - loss: 0.5787 - mae: 0.5270 - mse: 0.5787 - val_loss: 0.6034 - val_mae: 0.5328 - val_mse: 0.6034\nEpoch 26/100\n5798/5798 - 13s - 2ms/step - loss: 0.5768 - mae: 0.5259 - mse: 0.5768 - val_loss: 0.6029 - val_mae: 0.5339 - val_mse: 0.6029\nEpoch 27/100\n5798/5798 - 14s - 2ms/step - loss: 0.5763 - mae: 0.5257 - mse: 0.5763 - val_loss: 0.6020 - val_mae: 0.5325 - val_mse: 0.6020\nEpoch 28/100\n5798/5798 - 14s - 2ms/step - loss: 0.5748 - mae: 0.5254 - mse: 0.5748 - val_loss: 0.6028 - val_mae: 0.5308 - val_mse: 0.6028\nEpoch 29/100\n5798/5798 - 14s - 2ms/step - loss: 0.5728 - mae: 0.5248 - mse: 0.5728 - val_loss: 0.6063 - val_mae: 0.5394 - val_mse: 0.6063\nEpoch 30/100\n5798/5798 - 14s - 2ms/step - loss: 0.5725 - mae: 0.5247 - mse: 0.5725 - val_loss: 0.6053 - val_mae: 0.5299 - val_mse: 0.6053\nEpoch 31/100\n5798/5798 - 14s - 2ms/step - loss: 0.5707 - mae: 0.5233 - mse: 0.5707 - val_loss: 0.6023 - val_mae: 0.5358 - val_mse: 0.6023\nEpoch 32/100\n5798/5798 - 13s - 2ms/step - loss: 0.5706 - mae: 0.5237 - mse: 0.5706 - val_loss: 0.6041 - val_mae: 0.5374 - val_mse: 0.6041\nEpoch 32: early stopping\nRestoring model weights from the end of the best epoch: 27.\n\nTraining Duration: 437.49 seconds\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# --- 6. Model Evaluation and Denormalization ---\nprint(\"\\n--- 6. Model Evaluation on Test Set ---\")\n\n# Make predictions on the scaled test set\ny_pred_scaled = model.predict(X_test_processed, verbose=0).flatten()\n\n# Denormalize the predictions back to the original year scale\n# y_original = (y_scaled * std) + mean\ny_pred_denorm = (y_pred_scaled * target_std) + target_mean\n\n# Calculate evaluation metrics using the DENORMALIZED predictions and original labels\nmse = mean_squared_error(y_test_original, y_pred_denorm)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(y_test_original, y_pred_denorm)\nr2 = r2_score(y_test_original, y_pred_denorm)\n\nprint(f\"Mean Squared Error (MSE): {mse:.4f}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"R-squared (R²): {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:20:55.248848Z","iopub.execute_input":"2025-12-04T09:20:55.249548Z","iopub.status.idle":"2025-12-04T09:21:01.512719Z","shell.execute_reply.started":"2025-12-04T09:20:55.249518Z","shell.execute_reply":"2025-12-04T09:21:01.511964Z"}},"outputs":[{"name":"stdout","text":"\n--- 6. Model Evaluation on Test Set ---\nMean Squared Error (MSE): 73.3151\nRoot Mean Squared Error (RMSE): 8.5624\nMean Absolute Error (MAE): 5.8306\nR-squared (R²): 0.3840\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# --- 7. Interpretation of Results ---\nprint(\"\\n--- 7. Interpretation ---\")\n\nprint(f\"Target variable is the Song Release Year (average around {target_mean:.0f}).\")\nprint(f\"The Deep Learning model's average prediction error (MAE) is {mae:.2f} years.\")\n\nif r2 > 0.5:\n    print(\"The R-squared value suggests the MLP model explains a good portion of the variance in the target variable.\")\nelse:\n    print(\"The R-squared value indicates a moderate fit. Consider using more complex architectures or optimizing the hyperparameters (number of layers, neurons, and learning rate) further.\")\n\nprint(\"\\nTask Complete. The 'model' variable holds the fully trained TensorFlow/Keras model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:21:24.442195Z","iopub.execute_input":"2025-12-04T09:21:24.442963Z","iopub.status.idle":"2025-12-04T09:21:24.448158Z","shell.execute_reply.started":"2025-12-04T09:21:24.442933Z","shell.execute_reply":"2025-12-04T09:21:24.447248Z"}},"outputs":[{"name":"stdout","text":"\n--- 7. Interpretation ---\nTarget variable is the Song Release Year (average around 1998).\nThe Deep Learning model's average prediction error (MAE) is 5.83 years.\nThe R-squared value indicates a moderate fit. Consider using more complex architectures or optimizing the hyperparameters (number of layers, neurons, and learning rate) further.\n\nTask Complete. The 'model' variable holds the fully trained TensorFlow/Keras model.\n","output_type":"stream"}],"execution_count":28}]}